{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "here I implement word2vec with very simple example using tensorflow  \n",
    "word2vec is vector representation for words with similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data\n",
    "we will use only 10 sentences to create word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['king is a strong man', \n",
    "          'queen is a wise woman', \n",
    "          'boy is a young man',\n",
    "          'girl is a young woman',\n",
    "          'prince is a young king',\n",
    "          'princess is a young queen',\n",
    "          'man is strong', \n",
    "          'woman is pretty',\n",
    "          'prince is a boy will be king',\n",
    "          'princess is a girl will be queen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stop words\n",
    "In order for efficiency of creating word vector, we will remove commonly used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(corpus):\n",
    "    stop_words = ['is', 'a', 'will', 'be']\n",
    "    results = []\n",
    "    for text in corpus:\n",
    "        tmp = text.split(' ')\n",
    "        for stop_word in stop_words:\n",
    "            if stop_word in tmp:\n",
    "                tmp.remove(stop_word)\n",
    "        results.append(\" \".join(tmp))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = remove_stop_words(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for text in corpus:\n",
    "    for word in text.split(' '):\n",
    "        words.append(word)\n",
    "\n",
    "words = set(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we have word set by which we will have word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boy',\n",
       " 'girl',\n",
       " 'king',\n",
       " 'man',\n",
       " 'pretty',\n",
       " 'prince',\n",
       " 'princess',\n",
       " 'queen',\n",
       " 'strong',\n",
       " 'wise',\n",
       " 'woman',\n",
       " 'young'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data generation\n",
    "we will generate label for each word using skip gram.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : boy : <enumerate object at 0x7f57ce099990>\n",
      "1 : princess : <enumerate object at 0x7f57ce099990>\n",
      "2 : wise : <enumerate object at 0x7f57ce099990>\n",
      "3 : man : <enumerate object at 0x7f57ce099990>\n",
      "4 : queen : <enumerate object at 0x7f57ce099990>\n",
      "5 : young : <enumerate object at 0x7f57ce099990>\n",
      "6 : king : <enumerate object at 0x7f57ce099990>\n",
      "7 : woman : <enumerate object at 0x7f57ce099990>\n",
      "8 : pretty : <enumerate object at 0x7f57ce099990>\n",
      "9 : strong : <enumerate object at 0x7f57ce099990>\n",
      "10 : girl : <enumerate object at 0x7f57ce099990>\n",
      "11 : prince : <enumerate object at 0x7f57ce099990>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x=enumerate(words)\n",
    "for i, key in x:\n",
    "    print(i, \":\", key, \":\", x)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2int = {}\n",
    "\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for sentence in corpus:\n",
    "    sentences.append(sentence.split())\n",
    "    \n",
    "WINDOW_SIZE = 2\n",
    "\n",
    "data = []\n",
    "for sentence in sentences:\n",
    "    for idx, word in enumerate(sentence):\n",
    "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] : \n",
    "            if neighbor != word:\n",
    "                data.append([word, neighbor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king strong man\n",
      "queen wise woman\n",
      "boy young man\n",
      "girl young woman\n",
      "prince young king\n",
      "princess young queen\n",
      "man strong\n",
      "woman pretty\n",
      "prince boy king\n",
      "princess girl queen\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for text in corpus:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>king</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>king</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strong</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strong</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>man</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>queen</td>\n",
       "      <td>wise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>queen</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wise</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wise</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>woman</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>woman</td>\n",
       "      <td>wise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>boy</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>boy</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>young</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>young</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>man</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>man</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>girl</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>girl</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     input   label\n",
       "0     king  strong\n",
       "1     king     man\n",
       "2   strong    king\n",
       "3   strong     man\n",
       "4      man    king\n",
       "5      man  strong\n",
       "6    queen    wise\n",
       "7    queen   woman\n",
       "8     wise   queen\n",
       "9     wise   woman\n",
       "10   woman   queen\n",
       "11   woman    wise\n",
       "12     boy   young\n",
       "13     boy     man\n",
       "14   young     boy\n",
       "15   young     man\n",
       "16     man     boy\n",
       "17     man   young\n",
       "18    girl   young\n",
       "19    girl   woman"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns = ['input', 'label'])\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boy': 0,\n",
       " 'princess': 1,\n",
       " 'wise': 2,\n",
       " 'man': 3,\n",
       " 'queen': 4,\n",
       " 'young': 5,\n",
       " 'king': 6,\n",
       " 'woman': 7,\n",
       " 'pretty': 8,\n",
       " 'strong': 9,\n",
       " 'girl': 10,\n",
       " 'prince': 11}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "ONE_HOT_DIM = len(words)\n",
    "\n",
    "# function to convert numbers to one hot vectors\n",
    "def to_one_hot_encoding(data_point_index):\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
    "    one_hot_encoding[data_point_index] = 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "X = [] # input word\n",
    "Y = [] # target word\n",
    "\n",
    "for x, y in zip(df['input'], df['label']):\n",
    "    X.append(to_one_hot_encoding(word2int[ x ]))\n",
    "    Y.append(to_one_hot_encoding(word2int[ y ]))\n",
    "\n",
    "# convert them to numpy arrays\n",
    "X_train = np.asarray(X)\n",
    "Y_train = np.asarray(Y)\n",
    "\n",
    "# making placeholders for X_train and Y_train\n",
    "x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "\n",
    "# word embedding will be 2 dimension for 2d visualization\n",
    "EMBEDDING_DIM = 2 \n",
    "\n",
    "# hidden layer: which represents word vector eventually\n",
    "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([1])) #bias\n",
    "hidden_layer = tf.add(tf.matmul(x,W1), b1)\n",
    "\n",
    "# output layer\n",
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
    "\n",
    "# loss function: cross entropy\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
    "\n",
    "# training operation\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 loss is :  4.2430773\n",
      "iteration 3000 loss is :  1.819968\n",
      "iteration 6000 loss is :  1.7603772\n",
      "iteration 9000 loss is :  1.7254598\n",
      "iteration 12000 loss is :  1.6960016\n",
      "iteration 15000 loss is :  1.67986\n",
      "iteration 18000 loss is :  1.6718862\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) \n",
    "\n",
    "iteration = 20000\n",
    "for i in range(iteration):\n",
    "    # input is X_train which is one hot encoded word\n",
    "    # label is Y_train which is one hot encoded neighbor word\n",
    "    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n",
    "    if i % 3000 == 0:\n",
    "        print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0710007   0.09514606]\n",
      " [-3.3677328   5.024269  ]\n",
      " [-2.9036636   1.6153882 ]\n",
      " [ 2.3537946   0.97639406]\n",
      " [-0.5351625   0.6246869 ]\n",
      " [-0.07134229 -0.27618307]\n",
      " [ 0.78227353  0.09508654]\n",
      " [-0.9366918   1.6455181 ]\n",
      " [-1.5302083  -1.9121485 ]\n",
      " [ 5.928801    0.09705111]\n",
      " [-0.7791653   0.7740228 ]\n",
      " [ 5.1857433   1.7407856 ]]\n"
     ]
    }
   ],
   "source": [
    "# Now the hidden layer (W1 + b1) is actually the word look up table\n",
    "vectors = sess.run(W1 + b1)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word vector in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boy</td>\n",
       "      <td>1.071001</td>\n",
       "      <td>0.095146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>princess</td>\n",
       "      <td>-3.367733</td>\n",
       "      <td>5.024269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wise</td>\n",
       "      <td>-2.903664</td>\n",
       "      <td>1.615388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>man</td>\n",
       "      <td>2.353795</td>\n",
       "      <td>0.976394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queen</td>\n",
       "      <td>-0.535163</td>\n",
       "      <td>0.624687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>young</td>\n",
       "      <td>-0.071342</td>\n",
       "      <td>-0.276183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>king</td>\n",
       "      <td>0.782274</td>\n",
       "      <td>0.095087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>woman</td>\n",
       "      <td>-0.936692</td>\n",
       "      <td>1.645518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pretty</td>\n",
       "      <td>-1.530208</td>\n",
       "      <td>-1.912148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>strong</td>\n",
       "      <td>5.928801</td>\n",
       "      <td>0.097051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>girl</td>\n",
       "      <td>-0.779165</td>\n",
       "      <td>0.774023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>prince</td>\n",
       "      <td>5.185743</td>\n",
       "      <td>1.740786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word        x1        x2\n",
       "0        boy  1.071001  0.095146\n",
       "1   princess -3.367733  5.024269\n",
       "2       wise -2.903664  1.615388\n",
       "3        man  2.353795  0.976394\n",
       "4      queen -0.535163  0.624687\n",
       "5      young -0.071342 -0.276183\n",
       "6       king  0.782274  0.095087\n",
       "7      woman -0.936692  1.645518\n",
       "8     pretty -1.530208 -1.912148\n",
       "9     strong  5.928801  0.097051\n",
       "10      girl -0.779165  0.774023\n",
       "11    prince  5.185743  1.740786"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
    "w2v_df['word'] = words\n",
    "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word vector in 2d chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
    "    ax.annotate(word, (x1,x2 ))\n",
    "    \n",
    "PADDING = 1.0\n",
    "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
    "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
    "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
    "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
    " \n",
    "plt.xlim(x_axis_min,x_axis_max)\n",
    "plt.ylim(y_axis_min,y_axis_max)\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
